{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense network\n",
    "\n",
    ">*Finally, try with neural networks*\n",
    ">* *1-layer dense network i.e. no hidden layer, just the input and output ones*\n",
    ">* *2-layer dense network i.e. one hidden layer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/exts-ml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/envs/exts-ml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/envs/exts-ml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/envs/exts-ml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/envs/exts-ml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/envs/exts-ml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Import the packages needed \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to start by loading features and labels from all the sets (train, validation and test sets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features and labels from npz files\n",
    "with np.load('train.npz', allow_pickle=False) as npz_file:\n",
    "    X_train=npz_file['features']\n",
    "    y_train=npz_file['labels']\n",
    "\n",
    "with np.load('valid.npz', allow_pickle=False) as npz_file:\n",
    "    X_valid=npz_file['features']\n",
    "    y_valid=npz_file['labels']\n",
    "\n",
    "with np.load('test.npz', allow_pickle=False) as npz_file:\n",
    "    X_test=npz_file['features']\n",
    "    y_test=npz_file['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-layer dense network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to implement a 1-layer fully-connected (dense) neural network with keras api. Let's start by creating the model and add the layer with 6 units as there are 6 categories of images. The input dimension corresponds to the shape of the features for one image. I am also going to print a summary of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 6)                 7686      \n",
      "=================================================================\n",
      "Total params: 7,686\n",
      "Trainable params: 7,686\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(6, activation='softmax', input_dim=1280))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to define the loss function, the optimizer and the metrics that I want to monitor with the compile function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function, optimizer and metrics to track during training\n",
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to fit the network using the train set and setting the validation data to the validation set in order to see the results on the validation set. I do not need to suffle as this was done when I saved the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 281 samples, validate on 139 samples\n",
      "Epoch 1/30\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 1.4432 - acc: 0.4769 - val_loss: 1.0588 - val_acc: 0.7410\n",
      "Epoch 2/30\n",
      "281/281 [==============================] - 0s 106us/step - loss: 0.8841 - acc: 0.7687 - val_loss: 0.7776 - val_acc: 0.7986\n",
      "Epoch 3/30\n",
      "281/281 [==============================] - 0s 105us/step - loss: 0.6527 - acc: 0.8470 - val_loss: 0.6410 - val_acc: 0.8129\n",
      "Epoch 4/30\n",
      "281/281 [==============================] - 0s 107us/step - loss: 0.5264 - acc: 0.8790 - val_loss: 0.5602 - val_acc: 0.8201\n",
      "Epoch 5/30\n",
      "281/281 [==============================] - 0s 106us/step - loss: 0.4459 - acc: 0.9075 - val_loss: 0.5065 - val_acc: 0.8417\n",
      "Epoch 6/30\n",
      "281/281 [==============================] - 0s 111us/step - loss: 0.3896 - acc: 0.9288 - val_loss: 0.4679 - val_acc: 0.8561\n",
      "Epoch 7/30\n",
      "281/281 [==============================] - 0s 108us/step - loss: 0.3477 - acc: 0.9359 - val_loss: 0.4388 - val_acc: 0.8633\n",
      "Epoch 8/30\n",
      "281/281 [==============================] - 0s 106us/step - loss: 0.3150 - acc: 0.9502 - val_loss: 0.4161 - val_acc: 0.8777\n",
      "Epoch 9/30\n",
      "281/281 [==============================] - 0s 108us/step - loss: 0.2886 - acc: 0.9537 - val_loss: 0.3977 - val_acc: 0.8921\n",
      "Epoch 10/30\n",
      "281/281 [==============================] - 0s 109us/step - loss: 0.2668 - acc: 0.9609 - val_loss: 0.3827 - val_acc: 0.8921\n",
      "Epoch 11/30\n",
      "281/281 [==============================] - 0s 110us/step - loss: 0.2484 - acc: 0.9609 - val_loss: 0.3701 - val_acc: 0.8921\n",
      "Epoch 12/30\n",
      "281/281 [==============================] - 0s 109us/step - loss: 0.2326 - acc: 0.9644 - val_loss: 0.3594 - val_acc: 0.8921\n",
      "Epoch 13/30\n",
      "281/281 [==============================] - 0s 107us/step - loss: 0.2189 - acc: 0.9644 - val_loss: 0.3502 - val_acc: 0.8849\n",
      "Epoch 14/30\n",
      "281/281 [==============================] - 0s 106us/step - loss: 0.2068 - acc: 0.9680 - val_loss: 0.3422 - val_acc: 0.8849\n",
      "Epoch 15/30\n",
      "281/281 [==============================] - 0s 109us/step - loss: 0.1961 - acc: 0.9715 - val_loss: 0.3353 - val_acc: 0.8849\n",
      "Epoch 16/30\n",
      "281/281 [==============================] - 0s 114us/step - loss: 0.1865 - acc: 0.9715 - val_loss: 0.3292 - val_acc: 0.8849\n",
      "Epoch 17/30\n",
      "281/281 [==============================] - 0s 110us/step - loss: 0.1778 - acc: 0.9751 - val_loss: 0.3238 - val_acc: 0.8849\n",
      "Epoch 18/30\n",
      "281/281 [==============================] - 0s 105us/step - loss: 0.1699 - acc: 0.9751 - val_loss: 0.3190 - val_acc: 0.8849\n",
      "Epoch 19/30\n",
      "281/281 [==============================] - 0s 113us/step - loss: 0.1627 - acc: 0.9786 - val_loss: 0.3147 - val_acc: 0.8921\n",
      "Epoch 20/30\n",
      "281/281 [==============================] - 0s 112us/step - loss: 0.1562 - acc: 0.9786 - val_loss: 0.3108 - val_acc: 0.8921\n",
      "Epoch 21/30\n",
      "281/281 [==============================] - 0s 111us/step - loss: 0.1501 - acc: 0.9786 - val_loss: 0.3073 - val_acc: 0.8921\n",
      "Epoch 22/30\n",
      "281/281 [==============================] - 0s 113us/step - loss: 0.1445 - acc: 0.9786 - val_loss: 0.3042 - val_acc: 0.8993\n",
      "Epoch 23/30\n",
      "281/281 [==============================] - 0s 126us/step - loss: 0.1393 - acc: 0.9786 - val_loss: 0.3013 - val_acc: 0.8993\n",
      "Epoch 24/30\n",
      "281/281 [==============================] - 0s 113us/step - loss: 0.1345 - acc: 0.9786 - val_loss: 0.2987 - val_acc: 0.8993\n",
      "Epoch 25/30\n",
      "281/281 [==============================] - 0s 115us/step - loss: 0.1300 - acc: 0.9786 - val_loss: 0.2963 - val_acc: 0.9065\n",
      "Epoch 26/30\n",
      "281/281 [==============================] - 0s 115us/step - loss: 0.1258 - acc: 0.9786 - val_loss: 0.2941 - val_acc: 0.9065\n",
      "Epoch 27/30\n",
      "281/281 [==============================] - 0s 124us/step - loss: 0.1218 - acc: 0.9858 - val_loss: 0.2921 - val_acc: 0.9065\n",
      "Epoch 28/30\n",
      "281/281 [==============================] - 0s 108us/step - loss: 0.1181 - acc: 0.9858 - val_loss: 0.2903 - val_acc: 0.9065\n",
      "Epoch 29/30\n",
      "281/281 [==============================] - 0s 104us/step - loss: 0.1146 - acc: 0.9858 - val_loss: 0.2886 - val_acc: 0.9137\n",
      "Epoch 30/30\n",
      "281/281 [==============================] - 0s 117us/step - loss: 0.1113 - acc: 0.9858 - val_loss: 0.2870 - val_acc: 0.9137\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "history = model.fit(\n",
    "    x=X_train, y=y_train, validation_data=(X_valid,y_valid),\n",
    "    batch_size=32, epochs=30, shuffle=False # No need for shuffling and this was done before training samples\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to compute the test accuracy and save it in a dataframe. At the end of this exercise I will save it in an csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 144us/step\n"
     ]
    }
   ],
   "source": [
    "(test_loss, test_accuracy) = model.evaluate(X_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666547457378"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "results=pd.DataFrame({\n",
    "        'model': ['1-layer nn'],\n",
    "        'test_accuracy': '{:.3f}'.format(test_accuracy)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-layer dense network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to implement a 2-layer fully-connected (dense) neural network with keras api. Let's start by creating the model and add two layers: one with 16 units and one with 6 units as there are 6 categories of images. The input dimension corresponds to the shape of the features for one image. I am also going to print a summary of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                20496     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 20,598\n",
      "Trainable params: 20,598\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, activation='relu', input_dim=1280))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to define the loss function, the optimizer and the metrics that I want to monitor with the compile function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function, optimizer and metrics to track during training\n",
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to fit the network using the train set and setting the validation data to the validation set in order to see the results on the validation set. I do not need to suffle as this was done when I saved the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 281 samples, validate on 139 samples\n",
      "Epoch 1/30\n",
      "281/281 [==============================] - 1s 3ms/step - loss: 1.6010 - acc: 0.3203 - val_loss: 1.3704 - val_acc: 0.4676\n",
      "Epoch 2/30\n",
      "281/281 [==============================] - 0s 130us/step - loss: 1.2433 - acc: 0.5765 - val_loss: 1.1364 - val_acc: 0.6043\n",
      "Epoch 3/30\n",
      "281/281 [==============================] - 0s 136us/step - loss: 1.0375 - acc: 0.6975 - val_loss: 0.9867 - val_acc: 0.6619\n",
      "Epoch 4/30\n",
      "281/281 [==============================] - 0s 127us/step - loss: 0.8882 - acc: 0.7509 - val_loss: 0.8722 - val_acc: 0.7338\n",
      "Epoch 5/30\n",
      "281/281 [==============================] - 0s 125us/step - loss: 0.7719 - acc: 0.7865 - val_loss: 0.7812 - val_acc: 0.7842\n",
      "Epoch 6/30\n",
      "281/281 [==============================] - 0s 134us/step - loss: 0.6759 - acc: 0.8221 - val_loss: 0.7052 - val_acc: 0.8345\n",
      "Epoch 7/30\n",
      "281/281 [==============================] - 0s 149us/step - loss: 0.5948 - acc: 0.8683 - val_loss: 0.6406 - val_acc: 0.8489\n",
      "Epoch 8/30\n",
      "281/281 [==============================] - 0s 129us/step - loss: 0.5246 - acc: 0.8897 - val_loss: 0.5851 - val_acc: 0.8705\n",
      "Epoch 9/30\n",
      "281/281 [==============================] - 0s 132us/step - loss: 0.4637 - acc: 0.9110 - val_loss: 0.5379 - val_acc: 0.8633\n",
      "Epoch 10/30\n",
      "281/281 [==============================] - 0s 125us/step - loss: 0.4118 - acc: 0.9359 - val_loss: 0.4987 - val_acc: 0.8705\n",
      "Epoch 11/30\n",
      "281/281 [==============================] - 0s 126us/step - loss: 0.3682 - acc: 0.9395 - val_loss: 0.4656 - val_acc: 0.8705\n",
      "Epoch 12/30\n",
      "281/281 [==============================] - 0s 124us/step - loss: 0.3307 - acc: 0.9466 - val_loss: 0.4376 - val_acc: 0.8777\n",
      "Epoch 13/30\n",
      "281/281 [==============================] - 0s 126us/step - loss: 0.2991 - acc: 0.9573 - val_loss: 0.4145 - val_acc: 0.8777\n",
      "Epoch 14/30\n",
      "281/281 [==============================] - 0s 132us/step - loss: 0.2726 - acc: 0.9680 - val_loss: 0.3951 - val_acc: 0.8849\n",
      "Epoch 15/30\n",
      "281/281 [==============================] - 0s 133us/step - loss: 0.2497 - acc: 0.9715 - val_loss: 0.3791 - val_acc: 0.8849\n",
      "Epoch 16/30\n",
      "281/281 [==============================] - 0s 125us/step - loss: 0.2302 - acc: 0.9715 - val_loss: 0.3653 - val_acc: 0.8849\n",
      "Epoch 17/30\n",
      "281/281 [==============================] - 0s 151us/step - loss: 0.2133 - acc: 0.9715 - val_loss: 0.3537 - val_acc: 0.8849\n",
      "Epoch 18/30\n",
      "281/281 [==============================] - 0s 155us/step - loss: 0.1986 - acc: 0.9751 - val_loss: 0.3436 - val_acc: 0.8849\n",
      "Epoch 19/30\n",
      "281/281 [==============================] - 0s 146us/step - loss: 0.1855 - acc: 0.9751 - val_loss: 0.3350 - val_acc: 0.8921\n",
      "Epoch 20/30\n",
      "281/281 [==============================] - 0s 124us/step - loss: 0.1742 - acc: 0.9751 - val_loss: 0.3278 - val_acc: 0.8921\n",
      "Epoch 21/30\n",
      "281/281 [==============================] - 0s 122us/step - loss: 0.1643 - acc: 0.9751 - val_loss: 0.3214 - val_acc: 0.8921\n",
      "Epoch 22/30\n",
      "281/281 [==============================] - 0s 133us/step - loss: 0.1552 - acc: 0.9786 - val_loss: 0.3159 - val_acc: 0.8921\n",
      "Epoch 23/30\n",
      "281/281 [==============================] - 0s 141us/step - loss: 0.1473 - acc: 0.9822 - val_loss: 0.3111 - val_acc: 0.8921\n",
      "Epoch 24/30\n",
      "281/281 [==============================] - 0s 126us/step - loss: 0.1399 - acc: 0.9858 - val_loss: 0.3067 - val_acc: 0.8921\n",
      "Epoch 25/30\n",
      "281/281 [==============================] - 0s 130us/step - loss: 0.1334 - acc: 0.9858 - val_loss: 0.3028 - val_acc: 0.8921\n",
      "Epoch 26/30\n",
      "281/281 [==============================] - 0s 131us/step - loss: 0.1276 - acc: 0.9858 - val_loss: 0.2996 - val_acc: 0.8921\n",
      "Epoch 27/30\n",
      "281/281 [==============================] - 0s 127us/step - loss: 0.1223 - acc: 0.9858 - val_loss: 0.2962 - val_acc: 0.8921\n",
      "Epoch 28/30\n",
      "281/281 [==============================] - 0s 124us/step - loss: 0.1170 - acc: 0.9858 - val_loss: 0.2936 - val_acc: 0.8921\n",
      "Epoch 29/30\n",
      "281/281 [==============================] - 0s 125us/step - loss: 0.1125 - acc: 0.9858 - val_loss: 0.2911 - val_acc: 0.8921\n",
      "Epoch 30/30\n",
      "281/281 [==============================] - 0s 131us/step - loss: 0.1082 - acc: 0.9858 - val_loss: 0.2889 - val_acc: 0.8921\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "history = model.fit(\n",
    "    x=X_train, y=y_train, validation_data=(X_valid,y_valid),\n",
    "    batch_size=32, epochs=30, shuffle=False # No need for shuffling and this was done before training samples\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to compute the test accuracy, add it to the 1-layer nn results and save it in an csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 194us/step\n"
     ]
    }
   ],
   "source": [
    "(test_loss, test_accuracy) = model.evaluate(X_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666547457378"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "results2=pd.DataFrame({\n",
    "        'model': ['2-layer nn'],\n",
    "        'test_accuracy': '{:.3f}'.format(test_accuracy)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=results.append(results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to csv file with results\n",
    "pd.read_csv('results.csv').append(results).to_csv('results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
