{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction\n",
    "\n",
    ">*In this first part of the project, start by extracting a set of high-level features for each image in the data set. To achieve this, you can use ex. the Inception v3 or MobileNet v2 ConvNets which respectively extract 2048 and 1280 high-level features.*\n",
    "\n",
    ">*Suggestion: consider storing the extracted high-level features, e.g. in npz files, for quickly reloading them into each of the following notebooks.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/exts-ml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/envs/exts-ml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/envs/exts-ml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/envs/exts-ml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/envs/exts-ml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/envs/exts-ml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING:absl:Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "# Import the packages needed\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to load the images I am going to use the ImageDataGenerator. As the TensorFlow Hub image modules work with float32 images normalized between zero and one I am going to rescale the data and set the data type to float32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image generator\n",
    "\n",
    "generator = ImageDataGenerator(rescale=1/255, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For loading the images I am going to use the flow_from_directory from the ImageDataGenerator. I am going to set the image size to 224x224 as this is the expected input size when using MobileNetV2. I am going to suffle the train set but not the validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 281 images belonging to 6 classes.\n",
      "Found 139 images belonging to 6 classes.\n",
      "Found 50 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Train, validation and test sets\n",
    "\n",
    "trainset = generator.flow_from_directory(\n",
    "    os.path.join('swissroads', 'train'), batch_size=32, target_size=(224, 224), shuffle=True)\n",
    "validset = generator.flow_from_directory(\n",
    "    os.path.join('swissroads', 'valid'), batch_size=32, target_size=(224, 224), shuffle=False)\n",
    "testset = generator.flow_from_directory(\n",
    "    os.path.join('swissroads', 'test'), batch_size=32, target_size=(224, 224), shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I am going to download the module MobileNetV2 and create a graph with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# Create graph\n",
    "img_graph = tf.Graph()\n",
    "\n",
    "with img_graph.as_default():\n",
    "    # Download module\n",
    "    module_url = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/2'\n",
    "\n",
    "    feature_extractor = hub.Module(module_url)\n",
    "\n",
    "    # Create input placeholder\n",
    "    input_imgs = tf.placeholder(dtype=tf.float32, shape=[None, 224, 224, 3])\n",
    "\n",
    "    # A node with the features\n",
    "    imgs_features = feature_extractor(input_imgs)\n",
    "\n",
    "    # Collect initializers\n",
    "    init_op = tf.group([\n",
    "        tf.global_variables_initializer(), tf.tables_initializer()\n",
    "    ])\n",
    "\n",
    "img_graph.finalize() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the features with the graph created before and save them in three different npz files (one for the training, one for validation and one for testing). I am also going to save the images in these files as they will be needed for some tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = [trainset, validset, testset]\n",
    "file = ['train', 'valid', 'test']\n",
    "\n",
    "with tf.Session(graph=img_graph) as sess:\n",
    "    \n",
    "    # Initialize variables\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    # Going through all the sets (train, validation and test)\n",
    "    for i in np.arange(3):    \n",
    "        batches=0   \n",
    "    # Going through all the batches in each set \n",
    "        while batches <= sets[i].batch_index:\n",
    "            imgs, labels = sets[i].next()\n",
    "            # Extract features\n",
    "            features = sess.run(imgs_features, feed_dict={input_imgs: imgs})\n",
    "            # Save the features\n",
    "            if batches==0:\n",
    "                save_images=imgs\n",
    "                save_features=features\n",
    "                save_labels=labels\n",
    "            else:\n",
    "                save_images=np.append(save_images,imgs, axis=0)\n",
    "                save_features=np.append(save_features,features, axis=0)\n",
    "                save_labels=np.append(save_labels,labels, axis=0)\n",
    "            batches=batches+1\n",
    "        # Save a npz file for each set with images, features, labels and names\n",
    "        np.savez(file[i]+'.npz', images=save_images ,features=save_features, labels=np.argmax(save_labels, axis=1), names=list(sets[i].class_indices.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the images, features, labels and names of the classes were correctly saved in the npz files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train images: (281, 224, 224, 3)\n",
      "train features: (281, 1280)\n",
      "train labels: (281,)\n",
      "train names: (6,)\n",
      "valid images: (139, 224, 224, 3)\n",
      "valid features: (139, 1280)\n",
      "valid labels: (139,)\n",
      "valid names: (6,)\n",
      "test images: (50, 224, 224, 3)\n",
      "test features: (50, 1280)\n",
      "test labels: (50,)\n",
      "test names: (6,)\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(3):\n",
    "    # Load the npz file\n",
    "    with np.load(file[i]+'.npz', allow_pickle=False) as npz_file:\n",
    "        # Print the shape of the arrays\n",
    "        print(file[i]+' images:', npz_file['images'].shape)\n",
    "        print(file[i]+' features:', npz_file['features'].shape) \n",
    "        print(file[i]+' labels:', npz_file['labels'].shape)\n",
    "        print(file[i]+' names:', npz_file['names'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
